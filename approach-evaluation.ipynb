{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Approach Evaluation\n",
    "\n",
    "In this notebook, we evaluate the performance of our approach."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import rich.pretty\n",
    "\n",
    "rich.pretty.install()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import IPython.display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib as mpl\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import sklearn.metrics\n",
    "from sklearn.metrics import RocCurveDisplay\n",
    "import sqlalchemy as sa\n",
    "from sklearn.metrics import roc_curve\n",
    "import msgspec\n",
    "import itertools\n",
    "import pathlib as pl\n",
    "import networkx as nx\n",
    "import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from evaluatie import models as m\n",
    "from evaluatie import utils\n",
    "from evaluatie.data import FunctionDataset, DatasetOptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tqdm.tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mpl.rc(\n",
    "    \"font\",\n",
    "    size=12,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_table(dataset: FunctionDataset, score_col: str, all: bool = True) -> pd.DataFrame:\n",
    "    categories = [\n",
    "        \"low\",\n",
    "        \"medium\",\n",
    "        \"high\",\n",
    "    ]\n",
    "    if all:\n",
    "        categories.append(\"all\")\n",
    "\n",
    "    tbl = pd.DataFrame(\n",
    "        index=pd.Index(\n",
    "            categories,\n",
    "            name=\"neighborhood_size\",\n",
    "        ),\n",
    "        columns=pd.Index(\n",
    "            categories,\n",
    "            name=\"size\",\n",
    "        ),\n",
    "        dtype=np.float64,\n",
    "    )\n",
    "\n",
    "    for size, neighborhood_size in itertools.product(categories, categories):\n",
    "        options = DatasetOptions(\n",
    "            size=size,\n",
    "            neighborhood_size=neighborhood_size,\n",
    "        )\n",
    "        subset_df = dataset.frame[options.indexer(dataset.frame)]\n",
    "\n",
    "        fpr, tpr, _ = roc_curve(\n",
    "            y_score=subset_df[score_col],\n",
    "            y_true=subset_df[\"label\"],\n",
    "        )\n",
    "\n",
    "        tbl.loc[neighborhood_size, size] = sklearn.metrics.auc(fpr, tpr)\n",
    "\n",
    "    return tbl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BSim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = FunctionDataset.from_name(\"f:o0Xo2\")\n",
    "create_table(d, score_col=\"bsim\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = FunctionDataset.from_name(\"f:o0Xo3\")\n",
    "create_table(d, score_col=\"bsim\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = FunctionDataset.from_name(\"f:osXo0\")\n",
    "create_table(d, score_col=\"bsim\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = FunctionDataset.from_name(\"f:osXo2\")\n",
    "create_table(d, score_col=\"bsim\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = FunctionDataset.from_name(\"f:noinlineXinline\")\n",
    "create_table(d, score_col=\"bsim\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = FunctionDataset.from_name(\"f:x86Xarm\")\n",
    "create_table(d, score_col=\"bsim\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = FunctionDataset.from_name(\"f:armXmips\")\n",
    "create_table(d, score_col=\"bsim\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = FunctionDataset.from_name(\"f:x86Xmips\")\n",
    "create_table(d, score_col=\"bsim\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = FunctionDataset.from_name(\"f:malware-analysis\")\n",
    "create_table(d, score_col=\"bsim\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = FunctionDataset.from_name(\"f:firmware-analysis\")\n",
    "create_table(d, score_col=\"bsim\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = FunctionDataset.from_name(\"f:random\")\n",
    "create_table(d, score_col=\"bsim\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NeighBSim Evaluation [f:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name2dataset: dict[str, FunctionDataset] = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Takes 5 minutes for all datasets\n",
    "names = [\n",
    "    # Optimisation\n",
    "    # \"f:o0Xo2\",\n",
    "    # \"f:o0Xo2-overview\",\n",
    "    # \"f:o0Xo3\",\n",
    "    # \"f:o0Xo3-overview\",\n",
    "    # \"f:osXo0\",\n",
    "    # \"f:osXo0-overview\",\n",
    "    # \"f:osXo2\",\n",
    "    # \"f:osXo2-overview\",\n",
    "    # \"f:osXo3\",\n",
    "    # \"f:osXo3-overview\",\n",
    "    # Architecture\n",
    "    # \"f:armXmips\",\n",
    "    # \"f:armXmips-overview\",\n",
    "    # \"f:x86Xarm\",\n",
    "    # \"f:x86Xarm-overview\",\n",
    "    # \"f:x86Xmips\",\n",
    "    # \"f:x86Xmips-overview\",\n",
    "    # Misc\n",
    "    # \"f:random\",\n",
    "    # \"f:random-overview\",\n",
    "    # \"f:nopieXpie\",\n",
    "    # \"f:nopieXpie-overview\",\n",
    "    # \"f:noltoXlto\",\n",
    "    # \"f:noltoXlto-overview\",\n",
    "    # \"f:noinlineXinline\",\n",
    "    \"f:noinlineXinline-overview\",\n",
    "]\n",
    "\n",
    "for name in names:\n",
    "    print(f\"Loading {name}\")\n",
    "    if name in name2dataset:\n",
    "        continue\n",
    "    d = FunctionDataset.from_name(name)\n",
    "    d = d.load_pickle()\n",
    "    d = d.drop_metadata(\n",
    "        keep=[\n",
    "            \"qsize\",\n",
    "            \"qneighborhood_size\",\n",
    "            \"tsize\",\n",
    "            \"tneighborhood_size\",\n",
    "            # Required for testing Assumption 1.\n",
    "            # Comment out otherwise to save memory\n",
    "            \"caller_matching\",\n",
    "            \"callee_matching\",\n",
    "            \"qcallers\",\n",
    "            \"tcallers\",\n",
    "            \"qcallees\",\n",
    "            \"tcallees\",\n",
    "        ],\n",
    "    )\n",
    "\n",
    "    assert d.frame[\"bsim\"].isna().sum() == 0\n",
    "\n",
    "    name2dataset[name] = d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, d in name2dataset.items():\n",
    "    assert len(d.frame[d.frame[\"neighbsim\"].isna()]) == 0, f\"{name} has NaN's\"\n",
    "    # d.frame = d.frame.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name2label = {\n",
    "    \"f:x86Xarm\": \"x86 vs. arm\",\n",
    "    \"f:x86Xarm-overview\": \"x86 vs. arm\",\n",
    "    \"f:x86Xmips\": \"x86 vs. mips\",\n",
    "    \"f:x86Xmips-overview\": \"x86 vs. mips\",\n",
    "    \"f:armXmips\": \"arm vs. mips\",\n",
    "    \"f:armXmips-overview\": \"arm vs. mips\",\n",
    "    \"f:o0Xo2\": \"O0 vs. O2\",\n",
    "    \"f:o0Xo2-overview\": \"O0 vs. O2\",\n",
    "    \"f:o0Xo3\": \"O0 vs. O3\",\n",
    "    \"f:o0Xo3-overview\": \"O0 vs. O3\",\n",
    "    \"f:osXo0\": \"Os vs. O0\",\n",
    "    \"f:osXo0-overview\": \"Os vs. O0\",\n",
    "    \"f:osXo2\": \"Os vs. O2\",\n",
    "    \"f:osXo2-overview\": \"Os vs. O2\",\n",
    "    \"f:osXo3\": \"Os vs. O3\",\n",
    "    \"f:osXo3-overview\": \"Os vs. O3\",\n",
    "    \"f:noinlineXinline\": \"noinline vs. inline\",\n",
    "    \"f:noinlineXinline-overview\": \"noinline vs. inline\",\n",
    "    \"f:noltoXlto\": \"LTO\",\n",
    "    \"f:noltoXlto-overview\": \"LTO\",\n",
    "    \"f:nopieXpie\": \"PIE\",\n",
    "    \"f:nopieXpie-overview\": \"PIE\",\n",
    "    \"f:random\": \"Random\",\n",
    "    \"f:random-overview\": \"Random\",\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distributions of Sampled Data\n",
    "This can be used to explain several pehonmenons that we see in our results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = FunctionDataset.from_name(\"f:armXmips\")\n",
    "d = d.load_pickle()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = d.frame.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"qneighbor\"] = df[\"qcallees\"].apply(len) + df[\"qcallers\"].apply(len)\n",
    "df[\"tneighbor\"] = df[\"tcallees\"].apply(len) + df[\"tcallers\"].apply(len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(\n",
    "    data=df[(df[\"qneighbor\"] < 50) & (df[\"qneighborhood_size\"] == \"high\")],\n",
    "    x=\"qneighbor\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### When BSim outperforms NeighBSim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, d in name2dataset.items():\n",
    "    print()\n",
    "    print(name)\n",
    "    bsim = (\n",
    "        create_table(\n",
    "            d,\n",
    "            score_col=\"bsim\",\n",
    "            all=False,\n",
    "        )\n",
    "        .stack()\n",
    "        .reset_index(\n",
    "            name=\"score\",\n",
    "        )\n",
    "    )\n",
    "\n",
    "    neighbsim = (\n",
    "        create_table(\n",
    "            d,\n",
    "            score_col=\"neighbsim\",\n",
    "            all=False,\n",
    "        )\n",
    "        .stack()\n",
    "        .reset_index(\n",
    "            name=\"score\",\n",
    "        )\n",
    "    )\n",
    "\n",
    "    print(bsim[bsim[\"score\"] > neighbsim[\"score\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bsim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = FunctionDataset.from_name(\"f:o0Xo2\")\n",
    "d = d.load_pickle()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opts = DatasetOptions(\n",
    "    size=\"high\",\n",
    "    neighborhood_size=\"high\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = d.frame[opts.indexer(d.frame)].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[(df[\"label\"] == False) & (df[\"neighbsim\"] > 0.4)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def avg_edge_weight(graph: nx.Graph) -> float | None:\n",
    "    if len(graph.edges) == 0:\n",
    "        return None\n",
    "\n",
    "    return float(\n",
    "        np.average(\n",
    "            [weight for _, _, weight in graph.edges(data=\"weight\")],\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"avg_callee_edge\"] = df[\"callee_matching\"].apply(avg_edge_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(\n",
    "    data=df,\n",
    "    x=\"avg_callee_edge\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Score-Distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_col2label = {\n",
    "    \"bsim\": \"BSim\",\n",
    "    \"neighbsim\": \"NeighBSim\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_kde(\n",
    "    d: FunctionDataset,\n",
    "    score_col: str,\n",
    "    ax: mpl.axis.Axis,\n",
    "    dataset_options: DatasetOptions | None = None,\n",
    "):\n",
    "    plot_df = d.frame.copy()\n",
    "    if dataset_options is not None:\n",
    "        plot_df = plot_df.loc[dataset_options.indexer(plot_df)]\n",
    "\n",
    "    plot_df[\"label\"] = plot_df[\"label\"].map(\n",
    "        {\n",
    "            True: \"Positive\",\n",
    "            False: \"Negative\",\n",
    "        },\n",
    "    )\n",
    "\n",
    "    sns.kdeplot(\n",
    "        data=plot_df,\n",
    "        x=score_col,\n",
    "        hue=\"label\",\n",
    "        cut=0,\n",
    "        clip=(0, 1),\n",
    "        fill=True,\n",
    "        common_norm=False,\n",
    "        ax=ax,\n",
    "    )\n",
    "\n",
    "    ax.set_xlim(0, 1)\n",
    "    ax.set_xlabel(score_col2label[score_col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_score_distribution_subplots(*, name: str, score_col: str):\n",
    "    fig, axs = plt.subplots(\n",
    "        nrows=3,\n",
    "        ncols=3,\n",
    "        # Turned off to set labels for each axis individually\n",
    "        sharex=False,\n",
    "        sharey=True,\n",
    "    )\n",
    "\n",
    "    def opts_from_idx(*, row, col):\n",
    "        idx2bin = {\n",
    "            0: \"low\",\n",
    "            1: \"medium\",\n",
    "            2: \"high\",\n",
    "        }\n",
    "\n",
    "        return DatasetOptions(\n",
    "            size=idx2bin[col],\n",
    "            neighborhood_size=idx2bin[row],\n",
    "        )\n",
    "\n",
    "    for row, col_axs in enumerate(axs):\n",
    "        for col, ax in enumerate(col_axs):\n",
    "            opts = opts_from_idx(\n",
    "                row=row,\n",
    "                col=col,\n",
    "            )\n",
    "            plot_kde(\n",
    "                name2dataset[name],\n",
    "                score_col=score_col,\n",
    "                ax=ax,\n",
    "                dataset_options=opts,\n",
    "            )\n",
    "\n",
    "            ax.set_xticklabels([])\n",
    "            ax.set_xlabel(\"Score\")\n",
    "            ax.set_ylabel(\"Density\")\n",
    "\n",
    "            ax.yaxis.set_label_position(\"right\")\n",
    "            # Needed to make the label show up on the rightmost plot, not on the\n",
    "            # leftmost\n",
    "            ax.yaxis.tick_right()\n",
    "            ax.tick_params(axis=\"y\", labelright=True)\n",
    "\n",
    "    # Somehow we cannot call this ins the above loop\n",
    "    for ax in axs.flatten():\n",
    "        ax.label_outer()\n",
    "\n",
    "    axs[0][0].get_legend().remove()\n",
    "    axs[0][1].get_legend().remove()\n",
    "    # axs[0][2].get_legend().remove()\n",
    "    axs[1][0].get_legend().remove()\n",
    "    axs[1][1].get_legend().remove()\n",
    "    axs[1][2].get_legend().remove()\n",
    "    axs[2][0].get_legend().remove()\n",
    "    axs[2][1].get_legend().remove()\n",
    "    axs[2][2].get_legend().remove()\n",
    "\n",
    "    axs[0][2].get_legend().set_title(\"Label\")\n",
    "\n",
    "    axs[0][0].set_title(\n",
    "        \"Low\",\n",
    "        loc=\"center\",\n",
    "    )\n",
    "    axs[0][1].set_title(\n",
    "        \"Medium\",\n",
    "        loc=\"center\",\n",
    "    )\n",
    "    axs[0][2].set_title(\n",
    "        \"High\",\n",
    "        loc=\"center\",\n",
    "    )\n",
    "\n",
    "    axs[0][0].set_title(\n",
    "        \"Low\",\n",
    "        loc=\"left\",\n",
    "        y=0.5,\n",
    "        rotation=\"vertical\",\n",
    "        va=\"center\",\n",
    "        x=-0.15,\n",
    "    )\n",
    "    axs[1][0].set_title(\n",
    "        \"Medium\",\n",
    "        loc=\"left\",\n",
    "        y=0.5,\n",
    "        rotation=\"vertical\",\n",
    "        va=\"center\",\n",
    "        x=-0.15,\n",
    "    )\n",
    "    axs[2][0].set_title(\n",
    "        \"High\",\n",
    "        loc=\"left\",\n",
    "        y=0.5,\n",
    "        rotation=\"vertical\",\n",
    "        va=\"center\",\n",
    "        x=-0.15,\n",
    "    )\n",
    "\n",
    "    xticks = [0, 0.5, 1]\n",
    "    axs[2][0].set_xticks(xticks)\n",
    "    axs[2][1].set_xticks(xticks)\n",
    "    axs[2][2].set_xticks(xticks)\n",
    "    axs[2][0].set_xticklabels([0.0, 0.5, 1.0])\n",
    "    axs[2][1].set_xticklabels([\"\", 0.5, \"\"])\n",
    "    axs[2][2].set_xticklabels([0.0, 0.5, 1.0])\n",
    "\n",
    "    axs[0][0].set_yticks([0, 10, 20])\n",
    "    axs[0][0].set_yticklabels([0, 10, \"\"])\n",
    "    axs[0][0].set_ylim(0, 20)\n",
    "\n",
    "    fig.subplots_adjust(\n",
    "        wspace=0,\n",
    "        hspace=0,\n",
    "    )\n",
    "\n",
    "    fig.suptitle(\n",
    "        \"#BasicBlocks\",\n",
    "    )\n",
    "    fig.supylabel(\n",
    "        \"#Neighbors\",\n",
    "        x=0.03,\n",
    "    )\n",
    "\n",
    "    return fig, axs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_col = \"bsim\"\n",
    "\n",
    "for name in [\n",
    "    # Optimisation\n",
    "    \"f:o0Xo2\",\n",
    "    \"f:o0Xo3\",\n",
    "    \"f:osXo0\",\n",
    "    \"f:osXo2\",\n",
    "    \"f:osXo3\",\n",
    "    # Architecture\n",
    "    \"f:armXmips\",\n",
    "    \"f:x86Xarm\",\n",
    "    \"f:x86Xmips\",\n",
    "    # Misc\n",
    "    \"f:noinlineXinline\",\n",
    "    \"f:nopieXpie\",\n",
    "    \"f:noltoXlto\",\n",
    "    \"f:random\",\n",
    "]:\n",
    "    score_col = \"bsim\"\n",
    "    fig, axs = create_score_distribution_subplots(\n",
    "        name=name,\n",
    "        score_col=score_col,\n",
    "    )\n",
    "    fig.savefig(f\"figures/score-dist/{name}-{score_col}.pdf\")\n",
    "\n",
    "    score_col = \"neighbsim\"\n",
    "    fig, axs = create_score_distribution_subplots(\n",
    "        name=name,\n",
    "        score_col=score_col,\n",
    "    )\n",
    "    fig.savefig(f\"figures/score-dist/{name}-{score_col}.pdf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (Neigh)BSim ROC Curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "import sklearn.metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def roc_curve_from_dataset(\n",
    "    d: FunctionDataset,\n",
    "    score_col: str,\n",
    "    opts: DatasetOptions | None = None,\n",
    "):\n",
    "    frame = d.frame\n",
    "    if opts is not None:\n",
    "        frame = d.frame[opts.indexer(frame)]\n",
    "\n",
    "    fpr, tpr, _ = sklearn.metrics.roc_curve(\n",
    "        y_true=frame[\"label\"],\n",
    "        y_score=frame[score_col],\n",
    "    )\n",
    "\n",
    "    return fpr, tpr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_roc(fpr, tpr, *, ax):\n",
    "    lines = ax.plot(\n",
    "        fpr,\n",
    "        tpr,\n",
    "        drawstyle=\"steps-post\",\n",
    "        clip_on=False,\n",
    "    )\n",
    "    assert len(lines) == 1\n",
    "    line = lines[0]\n",
    "\n",
    "    ax.set_xlabel(\"False-Positive Rate\")\n",
    "    ax.set_ylabel(\"True-Positive Rate\")\n",
    "\n",
    "    ax.set_aspect(\"equal\")\n",
    "    ax.set_xlim(\n",
    "        xmin=0,\n",
    "        xmax=1,\n",
    "    )\n",
    "    ax.set_ylim(\n",
    "        ymin=0,\n",
    "        ymax=1,\n",
    "    )\n",
    "\n",
    "    return line\n",
    "\n",
    "\n",
    "def plot_roc_random(ax):\n",
    "    ax.plot(\n",
    "        [0, 1],\n",
    "        [0, 1],\n",
    "        \"--\",\n",
    "        color=\"gray\",\n",
    "        label=\"Random\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = name2dataset[\"f:armXmips\"]\n",
    "e = name2dataset[\"f:o0Xo3\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_fpr, d_tpr = roc_curve_from_dataset(d, score_col=\"neighbsim\")\n",
    "sklearn.metrics.auc(d_fpr, d_tpr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "e_fpr, e_tpr = roc_curve_from_dataset(e, score_col=\"bsim\")\n",
    "sklearn.metrics.auc(e_fpr, e_tpr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax_roc = plt.subplots()\n",
    "\n",
    "line = plot_roc(\n",
    "    d_fpr,\n",
    "    d_tpr,\n",
    "    ax=ax_roc,\n",
    ")\n",
    "line.set_label(\"ARM vs. MIPS (NeighBSim)\")\n",
    "\n",
    "line = plot_roc(\n",
    "    e_fpr,\n",
    "    e_tpr,\n",
    "    ax=ax_roc,\n",
    ")\n",
    "line.set_label(\"O0 vs. O3 (BSim)\")\n",
    "\n",
    "plot_roc_random(\n",
    "    ax=ax_roc,\n",
    ")\n",
    "\n",
    "ax_roc.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig.savefig(\n",
    "    \"figures/roc.pdf\",\n",
    "    bbox_inches=\"tight\",\n",
    "    transparent=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Overview Bar Chart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.axis\n",
    "import matplotlib as mpl\n",
    "import matplotlib.cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def auc_from_dataset(d: FunctionDataset, score_col: str):\n",
    "    return sklearn.metrics.roc_auc_score(\n",
    "        y_true=d.frame[\"label\"],\n",
    "        y_score=d.frame[score_col],\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "values = []\n",
    "for d in name2dataset.values():\n",
    "    bsim_auc = auc_from_dataset(d, \"bsim\")\n",
    "    neighbsim_auc = auc_from_dataset(d, \"neighbsim\")\n",
    "\n",
    "    values.append((d.name, bsim_auc, \"bsim\"))\n",
    "    values.append((d.name, neighbsim_auc, \"neighbsim\"))\n",
    "\n",
    "df = pd.DataFrame(\n",
    "    data=values,\n",
    "    columns=[\n",
    "        \"name\",\n",
    "        \"auc\",\n",
    "        \"score\",\n",
    "    ],\n",
    ")\n",
    "\n",
    "\n",
    "df = pd.pivot(\n",
    "    df,\n",
    "    index=\"name\",\n",
    "    columns=\"score\",\n",
    "    values=\"auc\",\n",
    ")\n",
    "\n",
    "df = df.loc[\n",
    "    [\n",
    "        \"f:o0Xo2-overview\",\n",
    "        \"f:o0Xo3-overview\",\n",
    "        \"f:osXo0-overview\",\n",
    "        \"f:osXo2-overview\",\n",
    "        \"f:osXo3-overview\",\n",
    "        \"f:x86Xarm-overview\",\n",
    "        \"f:x86Xmips-overview\",\n",
    "        \"f:armXmips-overview\",\n",
    "        \"f:noinlineXinline-overview\",\n",
    "        \"f:noltoXlto-overview\",\n",
    "        \"f:nopieXpie-overview\",\n",
    "        \"f:random-overview\",\n",
    "    ]\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_auc(value):\n",
    "    return f\"{value:.3f}\".lstrip(\"0\")\n",
    "\n",
    "\n",
    "fig, ax_roc = plt.subplots(\n",
    "    figsize=(12, 4),\n",
    ")\n",
    "\n",
    "width = 0.35\n",
    "x = np.arange(len(df))\n",
    "\n",
    "rects = ax_roc.bar(\n",
    "    x=x,\n",
    "    height=df[\"bsim\"],\n",
    "    label=\"BSim\",\n",
    "    width=width,\n",
    "    color=\"green\",\n",
    ")\n",
    "ax_roc.bar_label(\n",
    "    rects,\n",
    "    padding=3,\n",
    "    fmt=format_auc,\n",
    "    rotation=0,\n",
    "    fontsize=\"x-small\",\n",
    ")\n",
    "\n",
    "rects = ax_roc.bar(\n",
    "    x=x + width,\n",
    "    height=df[\"neighbsim\"],\n",
    "    width=width,\n",
    "    label=\"NeighBSim\",\n",
    "    # color=\"crimson\",\n",
    "    color=\"tomato\",\n",
    ")\n",
    "ax_roc.bar_label(\n",
    "    rects,\n",
    "    padding=3,\n",
    "    fmt=format_auc,\n",
    "    rotation=0,\n",
    "    fontsize=\"x-small\",\n",
    ")\n",
    "\n",
    "ax_roc.set_ylim((0.9, 1.0))\n",
    "ax_roc.set_ylabel(\"AUC\")\n",
    "ax_roc.legend(\n",
    "    loc=\"lower left\",\n",
    ")\n",
    "\n",
    "ax_roc.set_yticks(np.arange(0.90, 1.01, 0.01))\n",
    "\n",
    "\n",
    "_ = ax_roc.set_xticks(\n",
    "    x + 0.5 * width,\n",
    "    labels=df.index.to_series().apply(lambda name: name2label[name]),\n",
    "    rotation=60,\n",
    "    fontsize=\"medium\",\n",
    ")\n",
    "\n",
    "ax_roc.grid(\n",
    "    color=\"grey\",\n",
    "    linewidth=0.4,\n",
    "    axis=\"y\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig.savefig(\n",
    "    \"figures/evaluation:neighbsim-vs-bsim-barchart.pdf\",\n",
    "    bbox_inches=\"tight\",\n",
    "    transparent=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Heatmaps "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.axis\n",
    "import matplotlib as mpl\n",
    "import matplotlib.cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_axis(ax):\n",
    "    # ax.invert_yaxis()\n",
    "    ax.xaxis.tick_top()\n",
    "    ax.xaxis.set_label_position(\"top\")\n",
    "\n",
    "    labels = [\n",
    "        \"Low\",\n",
    "        \"Medium\",\n",
    "        \"High\",\n",
    "    ]\n",
    "    ax.set_xticks(\n",
    "        ticks=np.arange(len(labels)),\n",
    "        labels=labels,\n",
    "    )\n",
    "    ax.set_yticks(\n",
    "        ticks=np.arange(len(labels)),\n",
    "        labels=labels,\n",
    "    )\n",
    "\n",
    "    ax.set_aspect(\n",
    "        \"equal\",\n",
    "    )\n",
    "\n",
    "    ax.set_xticks(\n",
    "        np.arange(len(labels)) - 0.5,\n",
    "        minor=True,\n",
    "    )\n",
    "    ax.set_yticks(\n",
    "        np.arange(len(labels)) - 0.5,\n",
    "        minor=True,\n",
    "    )\n",
    "    ax.grid(\n",
    "        visible=True,\n",
    "        color=\"black\",\n",
    "        which=\"minor\",\n",
    "    )\n",
    "\n",
    "    ax.tick_params(which=\"minor\", bottom=False, left=False, top=False, right=False)\n",
    "\n",
    "    ax.set_xlabel(\"#BasicBlocks\")\n",
    "    ax.set_ylabel(\"#Neighbors\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_heatmap(\n",
    "    d: FunctionDataset,\n",
    "    score_col: str,\n",
    "    ax,\n",
    "):\n",
    "    setup_axis(ax)\n",
    "\n",
    "    tbl = create_table(\n",
    "        d,\n",
    "        score_col=score_col,\n",
    "        all=False,\n",
    "    )\n",
    "\n",
    "    im = ax.imshow(\n",
    "        tbl.to_numpy(),\n",
    "        cmap=\"YlGn\",\n",
    "        vmin=0.9,\n",
    "        vmax=1.0,\n",
    "    )\n",
    "\n",
    "    for i in range(len(tbl.columns)):\n",
    "        for j in range(len(tbl)):\n",
    "            auc = tbl.iloc[j, i]\n",
    "            auc_str = \"{0:.3f}\".format(auc).lstrip(\"0\")\n",
    "            ax.text(\n",
    "                i,\n",
    "                j,\n",
    "                auc_str,\n",
    "                ha=\"center\",\n",
    "                va=\"center\",\n",
    "                color=\"black\",\n",
    "            )\n",
    "\n",
    "    return im"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def child_by_type(ax, ty):\n",
    "    children = [child for child in ax.get_children() if isinstance(child, ty)]\n",
    "    if len(children) > 1:\n",
    "        raise ValueError(f\"Multiple children of type {ty}\")\n",
    "\n",
    "    if len(children) == 0:\n",
    "        raise ValueError(f\"No children of type {ty}\")\n",
    "\n",
    "    return children[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_heatmap_figure(dataset_names: list[str], score_col: str):\n",
    "    size_per_dataset = 3\n",
    "    fig, axs = plt.subplots(\n",
    "        nrows=1,\n",
    "        ncols=len(dataset_names),\n",
    "        sharey=True,\n",
    "        figsize=(size_per_dataset * len(dataset_names), 3),\n",
    "    )\n",
    "\n",
    "    for name, ax_roc in zip(\n",
    "        dataset_names,\n",
    "        axs,\n",
    "    ):\n",
    "        d = name2dataset[name]\n",
    "        plot_heatmap(\n",
    "            d,\n",
    "            score_col=score_col,\n",
    "            ax=ax_roc,\n",
    "        )\n",
    "\n",
    "        ax_roc.set_title(\n",
    "            name2label[d.name],\n",
    "            y=0,\n",
    "            pad=-20,\n",
    "        )\n",
    "\n",
    "    for ax_roc in axs[1:]:\n",
    "        ax_roc.tick_params(\n",
    "            axis=\"y\",\n",
    "            left=False,\n",
    "            labelleft=False,\n",
    "            which=\"major\",\n",
    "        )\n",
    "        ax_roc.set_ylabel(None)\n",
    "\n",
    "    im = child_by_type(axs[0], matplotlib.image.AxesImage)\n",
    "    cbar = fig.colorbar(im, ax=axs)\n",
    "\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = create_heatmap_figure(\n",
    "    dataset_names=[\n",
    "        \"f:o0Xo2\",\n",
    "        \"f:o0Xo3\",\n",
    "        \"f:osXo0\",\n",
    "        \"f:osXo2\",\n",
    "        \"f:osXo3\",\n",
    "    ],\n",
    "    score_col=\"neighbsim\",\n",
    ")\n",
    "\n",
    "fig.savefig(\n",
    "    \"figures/heatmap-optimization-neighbsim.pdf\",\n",
    "    bbox_inches=\"tight\",\n",
    "    transparent=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = create_heatmap_figure(\n",
    "    dataset_names=[\n",
    "        \"f:o0Xo2\",\n",
    "        \"f:o0Xo3\",\n",
    "        \"f:osXo0\",\n",
    "        \"f:osXo2\",\n",
    "        \"f:osXo3\",\n",
    "    ],\n",
    "    score_col=\"bsim\",\n",
    ")\n",
    "\n",
    "fig.savefig(\n",
    "    \"figures/heatmap-optimization-bsim.pdf\",\n",
    "    bbox_inches=\"tight\",\n",
    "    transparent=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = create_heatmap_figure(\n",
    "    dataset_names=[\n",
    "        \"f:x86Xarm\",\n",
    "        \"f:x86Xmips\",\n",
    "        \"f:armXmips\",\n",
    "    ],\n",
    "    score_col=\"neighbsim\",\n",
    ")\n",
    "\n",
    "fig.savefig(\n",
    "    \"figures/heatmap-architecture-neighbsim.pdf\",\n",
    "    bbox_inches=\"tight\",\n",
    "    transparent=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = create_heatmap_figure(\n",
    "    dataset_names=[\n",
    "        \"f:x86Xarm\",\n",
    "        \"f:x86Xmips\",\n",
    "        \"f:armXmips\",\n",
    "    ],\n",
    "    score_col=\"bsim\",\n",
    ")\n",
    "\n",
    "fig.savefig(\n",
    "    \"figures/heatmap-architecture-bsim.pdf\",\n",
    "    bbox_inches=\"tight\",\n",
    "    transparent=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = create_heatmap_figure(\n",
    "    dataset_names=[\n",
    "        \"f:noinlineXinline\",\n",
    "        \"f:noltoXlto\",\n",
    "        \"f:nopieXpie\",\n",
    "        \"f:random\",\n",
    "    ],\n",
    "    score_col=\"neighbsim\",\n",
    ")\n",
    "\n",
    "fig.savefig(\n",
    "    \"figures/heatmap-misc-neighbsim.pdf\",\n",
    "    bbox_inches=\"tight\",\n",
    "    transparent=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = create_heatmap_figure(\n",
    "    dataset_names=[\n",
    "        \"f:noinlineXinline\",\n",
    "        \"f:noltoXlto\",\n",
    "        \"f:nopieXpie\",\n",
    "        \"f:random\",\n",
    "    ],\n",
    "    score_col=\"bsim\",\n",
    ")\n",
    "\n",
    "fig.savefig(\n",
    "    \"figures/heatmap-misc-bsim.pdf\",\n",
    "    bbox_inches=\"tight\",\n",
    "    transparent=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Other"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, d in name2dataset.items():\n",
    "    neighbsim_table = create_table(d, score_col=\"neighbsim\")\n",
    "    IPython.display.display(f\"{name} -- NeighBSim\")\n",
    "    IPython.display.display(neighbsim_table)\n",
    "\n",
    "    bsim_table = create_table(d, score_col=\"bsim\")\n",
    "    IPython.display.display(f\"{name} -- BSim\")\n",
    "    IPython.display.display(bsim_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bins = [\"low\", \"medium\", \"high\"]\n",
    "\n",
    "x = np.arange(len(bins) * len(name2dataset), step=len(name2dataset))\n",
    "inter_dataset_offset = 0.4\n",
    "intra_dataset_offset = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "markers = [\"o\", \"x\", \"1\", \"<\", \"D\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bin2line = {\n",
    "    \"low\": \"dotted\",\n",
    "    \"medium\": (0, (3, 1, 1, 1)),\n",
    "    \"high\": \"solid\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax_roc = plt.subplots(\n",
    "    figsize=(8, 12),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "marker_cycle = iter(markers)\n",
    "\n",
    "for i, dataset in enumerate(name2dataset.values()):\n",
    "    marker = next(marker_cycle)\n",
    "    bsim_table = create_table(dataset, \"bsim\").drop(columns=\"all\").drop(labels=\"all\")\n",
    "    neighbsim_table = create_table(dataset, \"neighbsim\").drop(columns=\"all\").drop(labels=\"all\")\n",
    "\n",
    "    dataset_offset = i * (inter_dataset_offset + 2 * intra_dataset_offset)\n",
    "\n",
    "    for j, size_bin in enumerate(bins):\n",
    "        offset = dataset_offset + j * intra_dataset_offset\n",
    "\n",
    "        bsim_auc = bsim_table[size_bin]\n",
    "        neighbsim_auc = neighbsim_table[size_bin]\n",
    "\n",
    "        ymin = np.where(bsim_auc < neighbsim_auc, bsim_auc, neighbsim_auc)\n",
    "        ymax = np.where(bsim_auc > neighbsim_auc, bsim_auc, neighbsim_auc)\n",
    "        ax_roc.vlines(\n",
    "            x + offset, ymin=ymin, ymax=ymax, colors=\"grey\", linestyles=bin2line[size_bin]\n",
    "        )\n",
    "\n",
    "        rects = ax_roc.scatter(\n",
    "            x=x + offset,\n",
    "            y=bsim_auc,\n",
    "            # width=width,\n",
    "            label=size_bin,\n",
    "            color=\"mediumseagreen\",\n",
    "            alpha=1.0,\n",
    "            marker=marker,\n",
    "        )\n",
    "\n",
    "        rects = ax_roc.scatter(\n",
    "            x=x + offset,\n",
    "            y=neighbsim_auc,\n",
    "            # width=width,\n",
    "            label=size_bin,\n",
    "            color=\"tomato\",\n",
    "            alpha=1.0,\n",
    "            marker=marker,\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Additional Plots\n",
    "As the logic above is quite generic, we use it to create all sorts of plots that we use in the thesis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Background & Definitions: ROC Introduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opts = DatasetOptions(\n",
    "    size=\"high\",\n",
    "    neighborhood_size=\"low\",\n",
    ")\n",
    "\n",
    "left_dataset = name2dataset[\"f:noinlineXinline\"]\n",
    "right_dataset = name2dataset[\"f:o0Xo2\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax_left, ax_right, ax_roc) = plt.subplots(nrows=1, ncols=3, figsize=(14, 3))\n",
    "\n",
    "# Distributions\n",
    "plot_kde(\n",
    "    left_dataset,\n",
    "    score_col=\"bsim\",\n",
    "    ax=ax_left,\n",
    "    dataset_options=opts,\n",
    ")\n",
    "\n",
    "plot_kde(\n",
    "    right_dataset,\n",
    "    score_col=\"bsim\",\n",
    "    ax=ax_right,\n",
    "    dataset_options=opts,\n",
    ")\n",
    "\n",
    "# thresh = 0.6\n",
    "# height = ax_left.get_ylim()[1]\n",
    "# ax_left.vlines(\n",
    "#    thresh,\n",
    "#    ymin=0,\n",
    "#    ymax=height,\n",
    "#    colors=\"grey\",\n",
    "#    linestyles=\"dashed\",\n",
    "# )\n",
    "\n",
    "# thresh = 0.2\n",
    "# height = ax_right.get_ylim()[1]\n",
    "# ax_right.vlines(\n",
    "#    thresh,\n",
    "#    ymin=0,\n",
    "#    ymax=height,\n",
    "#    colors=\"grey\",\n",
    "#    linestyles=\"dashed\",\n",
    "# )\n",
    "\n",
    "ax_left.get_legend().set_loc(\"upper left\")\n",
    "\n",
    "\n",
    "# ROC Plot\n",
    "ltpr, lfpr = roc_curve_from_dataset(left_dataset, score_col=\"bsim\", opts=opts)\n",
    "line = plot_roc(ltpr, lfpr, ax=ax_roc)\n",
    "line.set_color(\"olivedrab\")\n",
    "line.set_label(\"Left\")\n",
    "\n",
    "\n",
    "rtpr, rfpr = roc_curve_from_dataset(right_dataset, score_col=\"bsim\", opts=opts)\n",
    "line = plot_roc(rtpr, rfpr, ax=ax_roc)\n",
    "line.set_color(\"firebrick\")\n",
    "line.set_label(\"Right\")\n",
    "\n",
    "plot_roc_random(\n",
    "    ax=ax_roc,\n",
    ")\n",
    "\n",
    "ax_left.get_legend().set_title(\"Label\")\n",
    "ax_right.get_legend().set_title(\"Label\")\n",
    "\n",
    "ax_roc.set_xticks(ax_roc.get_yticks())\n",
    "\n",
    "\n",
    "_ = ax_roc.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig.savefig(\n",
    "    \"figures/basics:roc-example.pdf\",\n",
    "    bbox_inches=\"tight\",\n",
    "    transparent=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Does _Assumption 1_ hold, and how does maximum weight matching perform?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.patches\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colorblind_palette = sns.color_palette(\"colorblind\")\n",
    "green = colorblind_palette[2]\n",
    "red = colorblind_palette[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "id2name: dict = {}\n",
    "\n",
    "\n",
    "def populate_id2name():\n",
    "    ids = []\n",
    "    for d in name2dataset.values():\n",
    "        _ = d.frame[\"callee_matching\"].progress_apply(lambda matching: ids.extend(matching.nodes))\n",
    "        _ = d.frame[\"caller_matching\"].progress_apply(lambda matching: ids.extend(matching.nodes))\n",
    "\n",
    "    with m.Session() as session:\n",
    "        stmt = sa.select(\n",
    "            m.Function.id,\n",
    "            m.Function.name,\n",
    "        ).where(m.Function.id.in_(ids))\n",
    "\n",
    "        for id, name in session.execute(stmt):\n",
    "            id2name[id] = name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Takes roughly 30 seconds for two datasets\n",
    "populate_id2name()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def matching_is_correct(matching: nx.Graph):\n",
    "    # Do not count empty matchings as correct\n",
    "    if len(matching.edges) == 0:\n",
    "        return None\n",
    "\n",
    "    ret = True\n",
    "    for src_id, dst_id in matching.edges:\n",
    "        ret &= id2name[src_id] == id2name[dst_id]\n",
    "\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _function_sets_are_equivalent(left: list, right: list):\n",
    "    if len(left) != len(right):\n",
    "        return False\n",
    "\n",
    "    left_names = {id2name[id] for id in left}\n",
    "    right_names = {id2name[id] for id in right}\n",
    "\n",
    "    return left_names == right_names\n",
    "\n",
    "\n",
    "def callees_changed(row):\n",
    "    qcallees = row[\"qcallees\"]\n",
    "    tcallees = row[\"tcallees\"]\n",
    "\n",
    "    return not _function_sets_are_equivalent(qcallees, tcallees)\n",
    "\n",
    "\n",
    "def callers_changed(row):\n",
    "    qcallers = row[\"qcallers\"]\n",
    "    tcallers = row[\"tcallers\"]\n",
    "\n",
    "    return not _function_sets_are_equivalent(qcallers, tcallers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_frame_from_dataset(d: FunctionDataset):\n",
    "    plot_df = d.frame[\n",
    "        # We are only interested in functions labeled as positive.\n",
    "        # For negative functions it is expected that the matching is wrong and the set of callers/callees changed\n",
    "        (d.frame[\"label\"] == True)\n",
    "        &\n",
    "        # Drop all columns that where either side of the bipartite graph is empty\n",
    "        (d.frame[\"caller_matching\"].apply(lambda matching: len(matching.edges)) != 0)\n",
    "        &\n",
    "        # Same for the callees\n",
    "        (d.frame[\"callee_matching\"].apply(lambda matching: len(matching.edges)) != 0)\n",
    "    ].copy()\n",
    "\n",
    "    plot_df[\"callees_changed\"] = d.frame.apply(callees_changed, axis=1)\n",
    "    plot_df[\"callers_changed\"] = d.frame.apply(callers_changed, axis=1)\n",
    "    plot_df[\"callee_matching_correct\"] = d.frame[\"callee_matching\"].apply(matching_is_correct)\n",
    "    plot_df[\"caller_matching_correct\"] = d.frame[\"caller_matching\"].apply(matching_is_correct)\n",
    "\n",
    "    return plot_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_from_plot_frame(plot_df: pd.DataFrame):\n",
    "    count = len(plot_df)\n",
    "    return {\n",
    "        \"pair-count\": count,\n",
    "        \"changed-callers\": plot_df[\"callers_changed\"].sum() / count,\n",
    "        \"changed-callees\": plot_df[\"callees_changed\"].sum() / count,\n",
    "        \"caller-matching-correct\": plot_df[\"caller_matching_correct\"].sum() / count,\n",
    "        \"callee-matching-correct\": plot_df[\"callee_matching_correct\"].sum() / count,\n",
    "        # Callers\n",
    "        \"callee-matching-correct-changed\": plot_df[plot_df[\"callees_changed\"] == True][\n",
    "            \"callee_matching_correct\"\n",
    "        ].sum()\n",
    "        / count,\n",
    "        \"callee-matching-correct-unchanged\": plot_df[plot_df[\"callees_changed\"] == False][\n",
    "            \"callee_matching_correct\"\n",
    "        ].sum()\n",
    "        / count,\n",
    "        # Callees\n",
    "        \"caller-matching-correct-changed\": plot_df[plot_df[\"callers_changed\"] == True][\n",
    "            \"caller_matching_correct\"\n",
    "        ].sum()\n",
    "        / count,\n",
    "        \"caller-matching-correct-unchanged\": plot_df[plot_df[\"callers_changed\"] == False][\n",
    "            \"caller_matching_correct\"\n",
    "        ].sum()\n",
    "        / count,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib as pl\n",
    "import pickle\n",
    "\n",
    "with pl.Path(\"datasets/neighborhood-correctness.pickle\").open(\"rb\") as f:\n",
    "    name2data = pickle.load(f)\n",
    "\n",
    "# name2data = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name2data = {\n",
    "    # Optimization\n",
    "    \"f:o0Xo2-overview\": name2data[\"f:o0Xo2-overview\"],\n",
    "    \"f:o0Xo3-overview\": name2data[\"f:o0Xo3-overview\"],\n",
    "    \"f:osXo0-overview\": name2data[\"f:osXo0-overview\"],\n",
    "    \"f:osXo2-overview\": name2data[\"f:osXo2-overview\"],\n",
    "    \"f:osXo3-overview\": name2data[\"f:osXo3-overview\"],\n",
    "    # Architecture\n",
    "    \"f:x86Xarm\": name2data[\"f:x86Xarm\"],\n",
    "    \"f:x86Xmips\": name2data[\"f:x86Xmips\"],\n",
    "    \"f:armXmips\": name2data[\"f:armXmips\"],\n",
    "    # Misc\n",
    "    \"f:noinlineXinline-overview\": name2data[\"f:noinlineXinline-overview\"],\n",
    "    \"f:noltoXlto-overview\": name2data[\"f:noltoXlto-overview\"],\n",
    "    \"f:nopieXpie-overview\": name2data[\"f:nopieXpie-overview\"],\n",
    "    \"f:random-overview\": name2data[\"f:random-overview\"],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_neighborhood_changes(caller_or_callee: str):\n",
    "    fig, ax = plt.subplots(\n",
    "        figsize=(12, 4),\n",
    "    )\n",
    "\n",
    "    for name, d in name2dataset.items():\n",
    "        if name in name2data:\n",
    "            continue\n",
    "        plot_df = plot_frame_from_dataset(d)\n",
    "        name2data[name] = data_from_plot_frame(plot_df)\n",
    "\n",
    "    width = 0.5\n",
    "    x = list(name2data.keys())\n",
    "\n",
    "    changed_callers = np.array(\n",
    "        [data[f\"changed-{caller_or_callee}s\"] for data in name2data.values()]\n",
    "    )\n",
    "    unchanged_callers = np.array([1 - v for v in changed_callers])\n",
    "\n",
    "    caller_matching_correct_changed = np.array(\n",
    "        [data[f\"{caller_or_callee}-matching-correct-changed\"] for data in name2data.values()]\n",
    "    )\n",
    "    caller_matching_correct_unchanged = np.array(\n",
    "        [data[f\"{caller_or_callee}-matching-correct-unchanged\"] for data in name2data.values()]\n",
    "    )\n",
    "\n",
    "    # Changed\n",
    "    ax.bar(\n",
    "        x=x,\n",
    "        bottom=0,\n",
    "        height=caller_matching_correct_changed,\n",
    "        width=width,\n",
    "        label=\"Changed\",\n",
    "        color=red,\n",
    "    )\n",
    "    ax.bar(\n",
    "        x=x,\n",
    "        bottom=caller_matching_correct_changed,\n",
    "        height=changed_callers - caller_matching_correct_changed,\n",
    "        width=width,\n",
    "        label=\"Changed\",\n",
    "        color=red,\n",
    "        alpha=0.7,\n",
    "    )\n",
    "\n",
    "    # Unchanged\n",
    "    ax.bar(\n",
    "        x=x,\n",
    "        bottom=1,\n",
    "        height=-caller_matching_correct_unchanged,\n",
    "        width=width,\n",
    "        label=\"Unchanged\",\n",
    "        color=green,\n",
    "    )\n",
    "    ax.bar(\n",
    "        x=x,\n",
    "        bottom=1 - caller_matching_correct_unchanged,\n",
    "        height=-(unchanged_callers - caller_matching_correct_unchanged),\n",
    "        width=width,\n",
    "        label=\"Unchanged\",\n",
    "        color=green,\n",
    "        alpha=0.7,\n",
    "    )\n",
    "\n",
    "    # Setup axes\n",
    "    ax.set_ylim(0, 1)\n",
    "    ax.set_yticks(np.arange(0, 1.1, 0.1))\n",
    "    xticks = ax.get_xticks()\n",
    "    ax.set_xticks(\n",
    "        xticks,\n",
    "        labels=[name2label[label.get_text()] for label in ax.get_xticklabels()],\n",
    "        rotation=60,\n",
    "    )\n",
    "\n",
    "    ax.grid(\n",
    "        color=\"grey\",\n",
    "        linewidth=0.4,\n",
    "        axis=\"y\",\n",
    "    )\n",
    "    ax.set_ylabel(\"Percentage\")\n",
    "\n",
    "    rect_correct = matplotlib.patches.Patch(\n",
    "        edgecolor=green,\n",
    "        facecolor=green + (0.7,),\n",
    "        linewidth=3,\n",
    "        label=\"Unchanged\",\n",
    "    )\n",
    "    rect_incorrect = matplotlib.patches.Patch(\n",
    "        edgecolor=red,\n",
    "        facecolor=red + (0.7,),\n",
    "        linewidth=3,\n",
    "        label=\"Changed\",\n",
    "    )\n",
    "\n",
    "    ax.legend(handles=[rect_correct, rect_incorrect])\n",
    "\n",
    "    return fig, ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plot_neighborhood_changes(\"callee\")\n",
    "\n",
    "fig.savefig(\n",
    "    \"figures/call-graph-matching-correctness-callee.pdf\",\n",
    "    bbox_inches=\"tight\",\n",
    "    transparent=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plot_neighborhood_changes(\"caller\")\n",
    "\n",
    "fig.savefig(\n",
    "    \"figures/call-graph-matching-correctness-caller.pdf\",\n",
    "    bbox_inches=\"tight\",\n",
    "    transparent=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Statistical Significance (DeLong Test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from MLstatkit.stats import Delong_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def p_values_from_dataset(d: FunctionDataset):\n",
    "    bins = [\"low\", \"medium\", \"high\"]\n",
    "\n",
    "    ret = pd.Series(\n",
    "        index=pd.MultiIndex.from_tuples(\n",
    "            itertools.product(bins, bins),\n",
    "            names=[\"size\", \"neighborhood_size\"],\n",
    "        )\n",
    "    )\n",
    "\n",
    "    for size in bins:\n",
    "        for neighborhood_size in bins:\n",
    "            opts = DatasetOptions(\n",
    "                size=size,\n",
    "                neighborhood_size=neighborhood_size,\n",
    "            )\n",
    "\n",
    "            df = d.frame[opts.indexer(d.frame)]\n",
    "\n",
    "            labels = df.label.apply(int)\n",
    "            bsim = df.bsim\n",
    "            neighbsim = df.neighbsim\n",
    "\n",
    "            z_score, p_val = Delong_test(\n",
    "                true=labels,\n",
    "                prob_A=bsim,\n",
    "                prob_B=neighbsim,\n",
    "            )\n",
    "\n",
    "            ret.loc[size, neighborhood_size] = p_val\n",
    "\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def p_value_from_dataset(d: FunctionDataset):\n",
    "    df = d.frame\n",
    "\n",
    "    labels = df.label.apply(int)\n",
    "    bsim = df.bsim\n",
    "    neighbsim = df.neighbsim\n",
    "\n",
    "    z_score, p_val = Delong_test(\n",
    "        true=labels,\n",
    "        prob_A=bsim,\n",
    "        prob_B=neighbsim,\n",
    "    )\n",
    "\n",
    "    return p_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bins = [\"low\", \"medium\", \"high\"]\n",
    "df = pd.DataFrame(\n",
    "    columns=list({name.removesuffix(\"-overview\") for name in name2dataset}),\n",
    "    index=pd.MultiIndex.from_tuples(\n",
    "        itertools.chain(itertools.product(bins, bins), [(\"all\", \"all\")]),\n",
    "        names=[\"size\", \"neighborhood_size\"],\n",
    "    ),\n",
    "    dtype=np.float128,\n",
    ")\n",
    "\n",
    "for name, d in name2dataset.items():\n",
    "    if name.endswith(\"-overview\"):\n",
    "        name = name.removesuffix(\"-overview\")\n",
    "        df.loc[(\"all\", \"all\"), name] = p_value_from_dataset(d)\n",
    "    else:\n",
    "        ret = p_values_from_dataset(d)\n",
    "        df.loc[ret.index, name] = ret\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"figures/significance.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"figures/significance.csv\").set_index([\"size\", \"neighborhood_size\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[\n",
    "    [\n",
    "        # Optimization\n",
    "        \"f:o0Xo2\",\n",
    "        \"f:o0Xo3\",\n",
    "        \"f:osXo0\",\n",
    "        \"f:osXo2\",\n",
    "        \"f:osXo3\",\n",
    "        # Architecture\n",
    "        \"f:x86Xarm\",\n",
    "        \"f:x86Xmips\",\n",
    "        \"f:armXmips\",\n",
    "        # Misc\n",
    "        \"f:noinlineXinline\",\n",
    "        \"f:noltoXlto\",\n",
    "        \"f:nopieXpie\",\n",
    "        \"f:random\",\n",
    "    ]\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_cell(p_value):\n",
    "    x = f\"{p_value:.2E}\"\n",
    "    num, exponent = x.split(\"E\")\n",
    "\n",
    "    ret = f\"${num} \\\\cdot 10^{{{exponent}}}$\"\n",
    "    if p_value >= 0.01:\n",
    "        ret = r\"\\cellcolor{lightgray}\" + ret\n",
    "\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.applymap(format_cell)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_row(row, comment):\n",
    "    row = row.apply(format_cell)\n",
    "\n",
    "    return \"& \" + \" & \".join(row) + f\" % {comment}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\n",
    "    [\n",
    "        # Architecture\n",
    "        \"f:x86Xarm\",\n",
    "        \"f:x86Xmips\",\n",
    "        \"f:armXmips\",\n",
    "    ]\n",
    "].apply(format_row, comment=\"Architecture\", axis=1).to_csv(\"/tmp/df.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\n",
    "    [\n",
    "        # Optimization\n",
    "        \"f:o0Xo2\",\n",
    "        \"f:o0Xo3\",\n",
    "        \"f:osXo0\",\n",
    "        \"f:osXo2\",\n",
    "        \"f:osXo3\",\n",
    "    ]\n",
    "].apply(format_row, comment=\"Optimization\", axis=1).to_csv(\"/tmp/df.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\n",
    "    [\n",
    "        # Misc\n",
    "        \"f:noinlineXinline\",\n",
    "        \"f:noltoXlto\",\n",
    "        \"f:nopieXpie\",\n",
    "        \"f:random\",\n",
    "    ]\n",
    "].apply(format_row, comment=\"Misc\", axis=1).to_csv(\"/tmp/df.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df >= 0.01"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Matching Weights vs. Function Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = name2dataset[\"f:o0Xo2-overview\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def avg_edge_weight(matching: nx.Graph):\n",
    "    weights = [data[\"weight\"] for _, _, data in matching.edges(data=True)]\n",
    "\n",
    "    if len(weights) == 0:\n",
    "        return np.nan\n",
    "\n",
    "    return sum(weights) / len(weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def avg_neighborhood_weight(row):\n",
    "    caller_matching = row[\"caller_matching\"]\n",
    "    callee_matching = row[\"callee_matching\"]\n",
    "\n",
    "    caller_avg = avg_edge_weight(caller_matching)\n",
    "    callee_avg = avg_edge_weight(callee_matching)\n",
    "\n",
    "    if np.isnan(caller_avg) and np.isnan(callee_avg):\n",
    "        return np.nan\n",
    "\n",
    "    if np.isnan(caller_avg):\n",
    "        return callee_avg\n",
    "\n",
    "    if np.isnan(callee_avg):\n",
    "        return caller_avg\n",
    "\n",
    "    return (caller_avg * len(caller_matching.edges) + callee_avg * len(caller_matching.edges)) / (\n",
    "        len(caller_matching.edges) + len(callee_matching.edges)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = d.frame\n",
    "df = df[(df[\"label\"] == True) & (df[\"qneighborhood_size\"] == \"high\")].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"avg\"] = df.apply(\n",
    "    avg_neighborhood_weight,\n",
    "    axis=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "step = 0.1\n",
    "bins = np.arange(\n",
    "    0,\n",
    "    1 + step,\n",
    "    step,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"bsim-bin\"] = pd.cut(\n",
    "    df[\"bsim\"],\n",
    "    bins=bins,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"avg-bin\"] = pd.cut(\n",
    "    df[\"avg\"],\n",
    "    bins=bins,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_df = pd.crosstab(index=df[\"bsim-bin\"], columns=df[\"avg-bin\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "sns.heatmap(\n",
    "    data=plot_df,\n",
    "    ax=ax,\n",
    ")\n",
    "\n",
    "ax.xaxis.tick_top()\n",
    "ax.xaxis.set_tick_params(rotation=300)\n",
    "ax.xaxis.set_label_position(\"top\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NeighBSim Evaluation [mrr:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import scipy.stats\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = [\n",
    "    \"mrr:o0Xo2\",\n",
    "    \"mrr:o0Xo3\",\n",
    "    \"mrr:osXo0\",\n",
    "    \"mrr:osXo2\",\n",
    "    \"mrr:osXo3\",\n",
    "    \"mrr:armXmips\",\n",
    "    \"mrr:x86Xarm\",\n",
    "    \"mrr:x86Xmips\",\n",
    "    \"mrr:noinlineXinline\",\n",
    "    #'mrr:noltoXlto',\n",
    "    \"mrr:nopieXpie\",\n",
    "    #'mrr:randomXrandom',\n",
    "]\n",
    "\n",
    "name2frame = {}\n",
    "\n",
    "for name in names:\n",
    "    print(name)\n",
    "    ranks_frame = pd.read_csv(f\"datasets/{name}-ranks.csv\", index_col=0)\n",
    "    firmup_frame = pd.read_csv(f\"datasets/{name}-firmup.csv\", index_col=0)[\n",
    "        [\"firmup\", \"firmup-steps\"]\n",
    "    ]\n",
    "    frame = pd.concat([ranks_frame, firmup_frame], axis=1)\n",
    "    name2frame[name] = frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name2label = {\n",
    "    \"mrr:x86Xarm\": \"x86 vs. arm\",\n",
    "    \"mrr:x86Xmips\": \"x86 vs. mips\",\n",
    "    \"mrr:armXmips\": \"arm vs. mips\",\n",
    "    \"mrr:o0Xo2\": \"O0 vs. O2\",\n",
    "    \"mrr:o0Xo3\": \"O0 vs. O3\",\n",
    "    \"mrr:osXo0\": \"Os vs. O0\",\n",
    "    \"mrr:osXo2\": \"Os vs. O2\",\n",
    "    \"mrr:osXo3\": \"Os vs. O3\",\n",
    "    \"mrr:noinlineXinline\": \"noinline vs. inline\",\n",
    "    \"mrr:noltoXlto\": \"LTO\",\n",
    "    \"mrr:nopieXpie\": \"PIE\",\n",
    "    \"mrr:random\": \"Random\",\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rank Distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_rank_distribution(frame: pd.DataFrame, *, score_col: str, ax):\n",
    "    plot_df = frame.copy()\n",
    "\n",
    "    sns.histplot(\n",
    "        data=plot_df,\n",
    "        x=score_col,\n",
    "        discrete=True,\n",
    "        stat=\"probability\",\n",
    "        label=score_col,\n",
    "        alpha=0.7,\n",
    "        ax=ax,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_rank_distribution2(frame: pd.DataFrame, *, ax):\n",
    "    plot_df = frame.copy()\n",
    "\n",
    "    plot_df = pd.melt(\n",
    "        plot_df,\n",
    "        id_vars=[\n",
    "            \"query_binary_id\",\n",
    "            \"target_binary_id\",\n",
    "            \"query_function_id\",\n",
    "            \"ptarget_function_id\",\n",
    "        ],\n",
    "        value_vars=[\"bsim_rank\", \"neighbsim_rank\"],\n",
    "        value_name=\"rank\",\n",
    "        var_name=\"score_col\",\n",
    "    )\n",
    "\n",
    "    sns.histplot(\n",
    "        data=plot_df,\n",
    "        x=\"rank\",\n",
    "        hue=\"score_col\",\n",
    "        discrete=True,\n",
    "        stat=\"probability\",\n",
    "        alpha=0.7,\n",
    "        ax=ax,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_rank_distribution_cumul(frame: pd.DataFrame, *, score_col: str, ax):\n",
    "    plot_df = frame.copy()\n",
    "\n",
    "    sns.histplot(\n",
    "        data=plot_df,\n",
    "        x=score_col,\n",
    "        discrete=True,\n",
    "        stat=\"probability\",\n",
    "        element=\"step\",\n",
    "        cumulative=True,\n",
    "        fill=False,\n",
    "        # label=score_col,\n",
    "        alpha=1.0,\n",
    "        ax=ax,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = [\n",
    "    \"mrr:o0Xo2\",\n",
    "    \"mrr:o0Xo3\",\n",
    "    \"mrr:osXo0\",\n",
    "    \"mrr:osXo2\",\n",
    "    \"mrr:osXo3\",\n",
    "]\n",
    "\n",
    "fig, axs = plt.subplots(\n",
    "    nrows=1,\n",
    "    ncols=len(names),\n",
    "    figsize=(15, 2.5),\n",
    "    sharex=True,\n",
    "    sharey=True,\n",
    ")\n",
    "\n",
    "\n",
    "max_rank = 10\n",
    "\n",
    "\n",
    "for ax in axs:\n",
    "    ax.set_xlim((0, max_rank))\n",
    "    ax.set_ylim(0, 1)\n",
    "\n",
    "    ax.set_xticks(np.arange(1, 11))\n",
    "    ax.set_yticks(np.arange(0, 1.1, 0.2))\n",
    "\n",
    "axs[0].set_ylabel(\"Percentage\")\n",
    "\n",
    "for (\n",
    "    ax,\n",
    "    name,\n",
    ") in zip(axs, names):\n",
    "    frame = name2frame[name]\n",
    "    plot_rank_distribution_cumul(\n",
    "        frame,\n",
    "        score_col=\"bsim_rank\",\n",
    "        ax=ax,\n",
    "    )\n",
    "\n",
    "    plot_rank_distribution_cumul(\n",
    "        frame,\n",
    "        score_col=\"neighbsim_rank\",\n",
    "        ax=ax,\n",
    "    )\n",
    "\n",
    "    ax.set_xlabel(\"Rank\")\n",
    "\n",
    "\n",
    "for (\n",
    "    ax,\n",
    "    name,\n",
    ") in zip(axs, names):\n",
    "    frame = name2frame[name]\n",
    "    plot_rank_distribution(\n",
    "        frame,\n",
    "        score_col=\"bsim_rank\",\n",
    "        ax=ax,\n",
    "    )\n",
    "\n",
    "    plot_rank_distribution(\n",
    "        frame,\n",
    "        score_col=\"neighbsim_rank\",\n",
    "        ax=ax,\n",
    "    )\n",
    "\n",
    "    ax.set_title(\n",
    "        name2label[name],\n",
    "    )\n",
    "# Omit legend here to only show it in the smaller architecture graph.\n",
    "# legend = axs[-1].legend(\n",
    "#     loc=\"upper left\",\n",
    "#     bbox_to_anchor=(1.02, 1),\n",
    "# )\n",
    "# score_col2text = {\n",
    "#     \"bsim_rank\": \"BSim\",\n",
    "#     \"neighbsim_rank\": \"NeighBSim\",\n",
    "# }\n",
    "# for text in legend.get_texts():\n",
    "#     text.set_text(score_col2text[text.get_text()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig.savefig(\n",
    "    \"figures/ranking:optimization.pdf\",\n",
    "    bbox_inches=\"tight\",\n",
    "    transparent=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = [\n",
    "    \"mrr:armXmips\",\n",
    "    \"mrr:x86Xarm\",\n",
    "    \"mrr:x86Xmips\",\n",
    "]\n",
    "\n",
    "fig, axs = plt.subplots(\n",
    "    nrows=1,\n",
    "    ncols=len(names),\n",
    "    figsize=(3 * len(names), 2.5),\n",
    "    sharex=True,\n",
    "    sharey=True,\n",
    ")\n",
    "\n",
    "\n",
    "max_rank = 10\n",
    "\n",
    "\n",
    "for ax in axs:\n",
    "    ax.set_xlim((0, max_rank))\n",
    "    ax.set_ylim(0, 1)\n",
    "\n",
    "    ax.set_xticks(np.arange(1, 11))\n",
    "    ax.set_yticks(np.arange(0, 1.1, 0.2))\n",
    "\n",
    "axs[0].set_ylabel(\"Percentage\")\n",
    "\n",
    "for (\n",
    "    ax,\n",
    "    name,\n",
    ") in zip(axs, names):\n",
    "    frame = name2frame[name]\n",
    "    plot_rank_distribution_cumul(\n",
    "        frame,\n",
    "        score_col=\"bsim_rank\",\n",
    "        ax=ax,\n",
    "    )\n",
    "\n",
    "    plot_rank_distribution_cumul(\n",
    "        frame,\n",
    "        score_col=\"neighbsim_rank\",\n",
    "        ax=ax,\n",
    "    )\n",
    "\n",
    "    ax.set_xlabel(\"Rank\")\n",
    "\n",
    "\n",
    "for (\n",
    "    ax,\n",
    "    name,\n",
    ") in zip(axs, names):\n",
    "    frame = name2frame[name]\n",
    "    plot_rank_distribution(\n",
    "        frame,\n",
    "        score_col=\"bsim_rank\",\n",
    "        ax=ax,\n",
    "    )\n",
    "\n",
    "    plot_rank_distribution(\n",
    "        frame,\n",
    "        score_col=\"neighbsim_rank\",\n",
    "        ax=ax,\n",
    "    )\n",
    "\n",
    "    ax.set_title(\n",
    "        name2label[name],\n",
    "    )\n",
    "\n",
    "legend = axs[-1].legend(\n",
    "    loc=\"upper left\",\n",
    "    bbox_to_anchor=(1.02, 1),\n",
    ")\n",
    "\n",
    "score_col2text = {\n",
    "    \"bsim_rank\": \"BSim\",\n",
    "    \"neighbsim_rank\": \"NeighBSim\",\n",
    "}\n",
    "for text in legend.get_texts():\n",
    "    text.set_text(score_col2text[text.get_text()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig.savefig(\n",
    "    \"figures/ranking:architecture.pdf\",\n",
    "    bbox_inches=\"tight\",\n",
    "    transparent=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = [\n",
    "    \"mrr:noinlineXinline\",\n",
    "    \"mrr:noltoXlto\",\n",
    "    \"mrr:nopieXpie\",\n",
    "    \"mrr:randomXrandom\",\n",
    "]\n",
    "\n",
    "fig, axs = plt.subplots(\n",
    "    nrows=1,\n",
    "    ncols=len(names),\n",
    "    figsize=(3 * len(names), 2.5),\n",
    "    sharex=True,\n",
    "    sharey=True,\n",
    ")\n",
    "\n",
    "\n",
    "max_rank = 10\n",
    "\n",
    "\n",
    "for ax in axs:\n",
    "    ax.set_xlim((0, max_rank))\n",
    "    ax.set_ylim(0, 1)\n",
    "\n",
    "    ax.set_xticks(np.arange(1, 11))\n",
    "    ax.set_yticks(np.arange(0, 1.1, 0.2))\n",
    "\n",
    "axs[0].set_ylabel(\"Percentage\")\n",
    "\n",
    "for (\n",
    "    ax,\n",
    "    name,\n",
    ") in zip(axs, names):\n",
    "    frame = name2frame[name]\n",
    "    plot_rank_distribution_cumul(\n",
    "        frame,\n",
    "        score_col=\"bsim_rank\",\n",
    "        ax=ax,\n",
    "    )\n",
    "\n",
    "    plot_rank_distribution_cumul(\n",
    "        frame,\n",
    "        score_col=\"neighbsim_rank\",\n",
    "        ax=ax,\n",
    "    )\n",
    "\n",
    "    ax.set_xlabel(\"Rank\")\n",
    "\n",
    "\n",
    "for (\n",
    "    ax,\n",
    "    name,\n",
    ") in zip(axs, names):\n",
    "    frame = name2frame[name]\n",
    "    plot_rank_distribution(\n",
    "        frame,\n",
    "        score_col=\"bsim_rank\",\n",
    "        ax=ax,\n",
    "    )\n",
    "\n",
    "    plot_rank_distribution(\n",
    "        frame,\n",
    "        score_col=\"neighbsim_rank\",\n",
    "        ax=ax,\n",
    "    )\n",
    "\n",
    "    ax.set_title(\n",
    "        name2label[name],\n",
    "    )\n",
    "\n",
    "legend = axs[-1].legend(\n",
    "    loc=\"upper left\",\n",
    "    bbox_to_anchor=(1.02, 1),\n",
    ")\n",
    "\n",
    "score_col2text = {\n",
    "    \"bsim_rank\": \"BSim\",\n",
    "    \"neighbsim_rank\": \"NeighBSim\",\n",
    "}\n",
    "for text in legend.get_texts():\n",
    "    text.set_text(score_col2text[text.get_text()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig.savefig(\n",
    "    \"figures/ranking:misc.pdf\",\n",
    "    bbox_inches=\"tight\",\n",
    "    transparent=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bsim failed pretty hard in comparing size optimization and no optimization\n",
    "frame = name2frame[\"mrr:osXo0\"]\n",
    "frame[frame[\"bsim_rank\"] == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How many functions from bsim rank two moved up by one in neighbsim\n",
    "frame = name2frame[\"mrr:o0Xo2\"]\n",
    "len(frame[(frame[\"bsim_rank\"] == 2) & (frame[\"neighbsim_rank\"] == 1)]) / len(\n",
    "    frame[frame[\"bsim_rank\"] == 2]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name2frame[\"mrr:o0Xo2\"][\"bsim_rank\"].max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparison to FirmUP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from evaluatie.firmup import firmup, FirmUPArgs\n",
    "from evaluatie import utils\n",
    "from evaluatie import models as m\n",
    "import networkx as nx\n",
    "import tqdm\n",
    "\n",
    "tqdm.tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_df = pd.DataFrame(\n",
    "    columns=list(name2frame),\n",
    "    index=[\"neighbsim\", \"bsim\", \"firmup\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, frame in name2frame.items():\n",
    "    firmup_percentage = (frame[\"firmup\"] == frame[\"ptarget_function_id\"]).sum() / len(frame)\n",
    "    bsim_percentage = (frame[\"bsim_rank\"] == 1).sum() / len(frame)\n",
    "    neighbsim_percentage = (frame[\"neighbsim_rank\"] == 1).sum() / len(frame)\n",
    "\n",
    "    plot_df.loc[\"firmup\", name] = firmup_percentage\n",
    "    plot_df.loc[\"bsim\", name] = bsim_percentage\n",
    "    plot_df.loc[\"neighbsim\", name] = neighbsim_percentage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_df = plot_df[\n",
    "    [\n",
    "        \"mrr:o0Xo2\",\n",
    "        \"mrr:o0Xo3\",\n",
    "        \"mrr:osXo0\",\n",
    "        \"mrr:osXo2\",\n",
    "        \"mrr:osXo3\",\n",
    "        \"mrr:x86Xarm\",\n",
    "        \"mrr:x86Xmips\",\n",
    "        \"mrr:armXmips\",\n",
    "        \"mrr:noinlineXinline\",\n",
    "        \"mrr:noltoXlto\",\n",
    "        \"mrr:nopieXpie\",\n",
    "        \"mrr:randomXrandom\",\n",
    "    ]\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_df.loc[\"firmup\"] - plot_df.loc[\"neighbsim\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def as_latex_percent(value: float):\n",
    "    percent = value * 100\n",
    "    return f\"${percent:.2f}\\\\%$\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def latex_line_from_row(row):\n",
    "    return \" & \".join([as_latex_percent(value) for value in row])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = plot_df.apply(\n",
    "    latex_line_from_row,\n",
    "    axis=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(x.firmup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(x.bsim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(x.neighbsim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ghidra Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pathlib as pl\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def date_from_line(line: str):\n",
    "    m = re.match(r\"\\[(.+?)\\: .+?\\]\", line)\n",
    "    assert m is not None\n",
    "\n",
    "    date_str = m.group(1)\n",
    "\n",
    "    return pd.to_datetime(date_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def worker_from_line(line: str):\n",
    "    m = re.match(r\".+ForkPoolWorker-(\\d+)\\]\", line)\n",
    "    if m is None:\n",
    "        return None\n",
    "\n",
    "    worker_str = m.group(1)\n",
    "    return int(worker_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lines = pl.Path(\"./celery.stderr\").read_text().splitlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "date_from_line(lines[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "worker_from_line(lines[100])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Uncategorized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from matplotlib.colors import LogNorm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\n",
    "    \"datasets/factors:raw.csv.gz\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"size\"].quantile(q=0.95)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"neighborhood_size\"].quantile(q=0.95)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = (\n",
    "    df[\n",
    "        [\n",
    "            \"size\",\n",
    "            \"neighborhood_size\",\n",
    "        ]\n",
    "    ][\n",
    "        (df[\"size\"] <= df[\"size\"].quantile(q=0.95))\n",
    "        & (df[\"neighborhood_size\"] <= df[\"neighborhood_size\"].quantile(q=0.95))\n",
    "    ]\n",
    "    .value_counts()\n",
    "    .unstack()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(\n",
    "    data,\n",
    "    norm=LogNorm(),\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "evaluatie-BmReXb80-py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
